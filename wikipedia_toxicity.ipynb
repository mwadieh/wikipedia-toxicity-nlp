{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "compatible-system",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "solid-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-franchise",
   "metadata": {},
   "source": [
    "### Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "located-balance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e617e2489abe9bca</td>\n",
       "      <td>\"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The De...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9250cf637294e09d</td>\n",
       "      <td>\"\\r\\n\\r\\nThis seems unbalanced.  whatever I ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce1aa4592d5240ca</td>\n",
       "      <td>Marya Dzmitruk was born in Minsk, Belarus in M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48105766ff7f075b</td>\n",
       "      <td>\"\\r\\n\\r\\nTalkback\\r\\n\\r\\n Dear Celestia...  \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0543d4f82e5470b6</td>\n",
       "      <td>New Categories \\r\\n\\r\\nI honestly think that w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic\n",
       "0  e617e2489abe9bca  \"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The De...      0\n",
       "1  9250cf637294e09d  \"\\r\\n\\r\\nThis seems unbalanced.  whatever I ha...      0\n",
       "2  ce1aa4592d5240ca  Marya Dzmitruk was born in Minsk, Belarus in M...      0\n",
       "3  48105766ff7f075b      \"\\r\\n\\r\\nTalkback\\r\\n\\r\\n Dear Celestia...  \"      0\n",
       "4  0543d4f82e5470b6  New Categories \\r\\n\\r\\nI honestly think that w...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data using read_csv\n",
    "df = pd.read_csv('wiki_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-williams",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "numeric-secretariat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e617e2489abe9bca</td>\n",
       "      <td>[barnstar, defender, wiki, barnstar, like, edi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9250cf637294e09d</td>\n",
       "      <td>[seems, unbalanced, whatever, said, mathsci, s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce1aa4592d5240ca</td>\n",
       "      <td>[marya, dzmitruk, born, minsk, belarus, march,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48105766ff7f075b</td>\n",
       "      <td>[talkback, dear, celestia]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0543d4f82e5470b6</td>\n",
       "      <td>[new, categories, honestly, think, need, add, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic\n",
       "0  e617e2489abe9bca  [barnstar, defender, wiki, barnstar, like, edi...      0\n",
       "1  9250cf637294e09d  [seems, unbalanced, whatever, said, mathsci, s...      0\n",
       "2  ce1aa4592d5240ca  [marya, dzmitruk, born, minsk, belarus, march,...      0\n",
       "3  48105766ff7f075b                         [talkback, dear, celestia]      0\n",
       "4  0543d4f82e5470b6  [new, categories, honestly, think, need, add, ...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to clean data\n",
    "def clean_text_data(text_data):\n",
    "    # removing ip address and normalising casing\n",
    "    text_data = [re.sub('[\\d+\\.{3}]\\d+',\"\",comment.lower()) for comment in text_data]\n",
    "\n",
    "    # removing URLs\n",
    "    text_data = [re.sub('\\w+://\\S+','',comment) for comment in text_data]\n",
    "\n",
    "    # removing \\r and \\n\n",
    "    text_data = [re.sub(r'[\\n\\r]','',comment) for comment in text_data]\n",
    "    df.head()\n",
    "\n",
    "    # removing \\'\n",
    "    text_data = [comment.replace(\"\\'\",\"\") for comment in text_data]\n",
    "\n",
    "    # performing word tokenization\n",
    "    text_data = [word_tokenize(comment) for comment in text_data]\n",
    "\n",
    "    \n",
    "    comments_stopwords = stopwords.words('english')\n",
    "    comments_punctuations = list(punctuation)\n",
    "    stopwords_punctuations = comments_stopwords + comments_punctuations + [\"''\",\"...\",\"``\",\"====\"]\n",
    "    \n",
    "    # function to remove stopwords and punctuations\n",
    "    def remove_stopwords(tokenized_comments):\n",
    "        return [tokens for tokens in tokenized_comments if tokens not in stopwords_punctuations]\n",
    "    \n",
    "    # removing stop words and punctuations\n",
    "    text_data = [remove_stopwords(comment) for comment in text_data]\n",
    "    \n",
    "    return text_data\n",
    "\n",
    "\n",
    "\n",
    "# cleaning comment_text column for training data\n",
    "df['comment_text'] = clean_text_data(df['comment_text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-democracy",
   "metadata": {},
   "source": [
    "### Using Counter to find top items in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "indirect-statistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('article', 1620),\n",
       " ('page', 1448),\n",
       " ('wikipedia', 1303),\n",
       " ('talk', 1171),\n",
       " ('please', 1003),\n",
       " ('ass', 985),\n",
       " ('would', 961),\n",
       " ('fuck', 903),\n",
       " ('one', 851),\n",
       " ('like', 832),\n",
       " ('dont', 775),\n",
       " ('also', 640),\n",
       " ('think', 628),\n",
       " ('see', 626),\n",
       " ('know', 595),\n",
       " ('edit', 557)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using counter to find top items in data\n",
    "merged_token_list = []\n",
    "for tokens in df['comment_text']:\n",
    "    merged_token_list.extend(tokens)\n",
    "\n",
    "counter_list = Counter(merged_token_list)\n",
    "counter_list.most_common(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mobile-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing top 5 most common words\n",
    "common_words = ['article','page','wikipedia','talk','please']\n",
    "\n",
    "# function to remove words\n",
    "def remove_words(tokenized_comments):\n",
    "        return [tokens for tokens in tokenized_comments if tokens not in common_words]\n",
    "\n",
    "final_tokens = [remove_words(word) for word in df['comment_text'] if word not in common_words]\n",
    "final_tokens = [\" \".join(word_list) for word_list in final_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-youth",
   "metadata": {},
   "source": [
    "### Separating into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bound-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining X and y values\n",
    "X = final_tokens\n",
    "y = df['toxic'].values\n",
    "\n",
    "# spliting data into training and testing datasets\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-fifteen",
   "metadata": {},
   "source": [
    "### Applying Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "foreign-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying tf-idf\n",
    "tfidfVec = TfidfVectorizer(max_features = 4000, ngram_range=(1,2))\n",
    "xtrain_trans = tfidfVec.fit_transform(xtrain)\n",
    "xtest_trans = tfidfVec.transform(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-applicant",
   "metadata": {},
   "source": [
    "### Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "characteristic-stereo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      3196\n",
      "           1       0.99      0.64      0.78       304\n",
      "\n",
      "    accuracy                           0.97      3500\n",
      "   macro avg       0.98      0.82      0.88      3500\n",
      "weighted avg       0.97      0.97      0.97      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating SVC estimator\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# fit training data\n",
    "svm_model.fit(xtrain_trans,ytrain)\n",
    "\n",
    "# predict using training data\n",
    "ypred_train = svm_model.predict(xtrain_trans)\n",
    "\n",
    "# predict using test data\n",
    "ypred_test = svm_model.predict(xtest_trans)\n",
    "\n",
    "# model evaluation (Accuracy, Recall and F1)\n",
    "print(classification_report(ytrain,ypred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-cigarette",
   "metadata": {},
   "source": [
    "The f1 score is relatively low for label '1'. This is due to the class imbalance, which can be seen in the 'support' column of the classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-elder",
   "metadata": {},
   "source": [
    "### Asjusting class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sized-singer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      3196\n",
      "           1       0.88      0.98      0.93       304\n",
      "\n",
      "    accuracy                           0.99      3500\n",
      "   macro avg       0.94      0.99      0.96      3500\n",
      "weighted avg       0.99      0.99      0.99      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# adjusted (balanced) svm model\n",
    "svm_balanced = SVC(kernel='linear',class_weight='balanced',random_state=42)\n",
    "\n",
    "# fit training data\n",
    "svm_balanced.fit(xtrain_trans,ytrain)\n",
    "\n",
    "# predict using training data\n",
    "ypred_train = svm_balanced.predict(xtrain_trans)\n",
    "\n",
    "# predict using test data\n",
    "ypred_test = svm_balanced.predict(xtest_trans)\n",
    "\n",
    "# model evaluation (Accuracy, Recall and F1)\n",
    "print(classification_report(ytrain,ypred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-playlist",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "executed-consumer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=SVC(class_weight='balanced', kernel='linear',\n",
       "                           random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000, 10000, 100000]},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dictionary for grid parameters\n",
    "grid_parameters = {'C':[0.1,1,10,100,1000,10000,100000]}\n",
    "\n",
    "# creating gridSearch model\n",
    "grid_search = GridSearchCV(estimator = svm_balanced, param_grid = grid_parameters,\n",
    "                           cv = StratifiedKFold(5), n_jobs = -1,verbose = 0, scoring = 'recall')\n",
    "\n",
    "# fitting data to gridSearch model\n",
    "grid_search.fit(xtrain_trans,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sexual-earth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, class_weight='balanced', kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieving best estimator parameters\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-hebrew",
   "metadata": {},
   "source": [
    "### Predicting test values with best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "material-picking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      1367\n",
      "           1       0.33      0.67      0.44       133\n",
      "\n",
      "    accuracy                           0.85      1500\n",
      "   macro avg       0.65      0.77      0.68      1500\n",
      "weighted avg       0.91      0.85      0.87      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicting test data using best estimator\n",
    "ypred_test = grid_search.best_estimator_.predict(xtest_trans)\n",
    "\n",
    "# model evaluation (Accuracy, Recall and F1)\n",
    "print(classification_report(ytest,ypred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-draft",
   "metadata": {},
   "source": [
    "### Most prominent terms in toxic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "about-deadline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nigger', 184),\n",
       " ('die', 157),\n",
       " ('jim', 157),\n",
       " ('wales', 156),\n",
       " ('must', 156),\n",
       " ('cuntbag', 126),\n",
       " ('fucking', 94),\n",
       " ('hate', 83),\n",
       " ('jews', 80),\n",
       " ('niggers', 79),\n",
       " ('spics', 79),\n",
       " ('minoritiesi', 79),\n",
       " ('dont', 23),\n",
       " ('go', 18),\n",
       " ('like', 17)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting toxic comments where ypred_test == 1 is True\n",
    "toxic_comments = pd.Series(xtest)[ypred_test == 1].values\n",
    "\n",
    "# using counter to find top words in data\n",
    "toxic_counter_list = []\n",
    "for comment in toxic_comments:\n",
    "    toxic_counter_list.extend(word_tokenize(comment))\n",
    "    \n",
    "toxic_word_count = Counter(toxic_counter_list)\n",
    "\n",
    "toxic_word_count.most_common(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
